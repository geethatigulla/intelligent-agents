{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJWV1cXidDwV",
        "outputId": "5e65097e-2e8a-4002-b950-ab0d78189c18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/12.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.5/12.0 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/12.0 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”\u001b[0m \u001b[32m10.4/12.0 MB\u001b[0m \u001b[31m120.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m11.9/12.0 MB\u001b[0m \u001b[31m178.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/278.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.1/278.1 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hâœ… All packages installed!\n"
          ]
        }
      ],
      "source": [
        "# Install packages\n",
        "!pip install langgraph langchain langchain-core litellm --quiet\n",
        "\n",
        "print(\"âœ… All packages installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up API key\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Get API key from user\n",
        "if 'GROQ_API_KEY' not in os.environ:\n",
        "    os.environ['GROQ_API_KEY'] = getpass('Enter your Groq API key: ')\n",
        "\n",
        "print(\"âœ… API key configured!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0KQSGCCdPic",
        "outputId": "4b2c6184-af18-4ec8-b180-f9b01c29a240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your Groq API key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "âœ… API key configured!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import core libraries\n",
        "from typing import TypedDict, Annotated, List, Literal\n",
        "import operator\n",
        "from litellm import completion\n",
        "import json\n",
        "\n",
        "# Helper function to call LLM\n",
        "def call_llm(prompt: str, system: str = \"You are a helpful assistant.\") -> str:\n",
        "    \"\"\"Simple wrapper for LLM calls.\"\"\"\n",
        "    try:\n",
        "        response = completion(\n",
        "            model=\"groq/llama-3.1-8b-instant\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=1024\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "# Test it\n",
        "print(call_llm(\"Say 'Multi-agent systems are awesome!' in exactly those words.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkVtsDxhdYGf",
        "outputId": "ef9ded00-752e-427b-a8c6-049f956e46aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multi-agent systems are awesome!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Define the researcher agent\n",
        "\n",
        "def researcher_agent(topic: str) -> str:\n",
        "    \"\"\"Researches a topic and returns key findings.\"\"\"\n",
        "    system = \"\"\"You are a research specialist. Your job is to:\n",
        "    1. Identify 3-4 key points about the given topic\n",
        "    2. Provide factual, concise information\n",
        "    3. Format as bullet points\n",
        "    Keep your response under 200 words.\"\"\"\n",
        "\n",
        "    # Create the prompt and call the LLM\n",
        "    prompt = f\"Research the topic: {topic}\"\n",
        "    return call_llm(prompt, system)\n",
        "\n",
        "# Test it\n",
        "# research = researcher_agent(\"benefits of meditation\")\n",
        "# print(research)\n"
      ],
      "metadata": {
        "id": "EqNfyYetdiox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Define the writer agent\n",
        "\n",
        "def writer_agent(research: str, topic: str) -> str:\n",
        "    \"\"\"Writes content based on research findings.\"\"\"\n",
        "    system = \"\"\"You are a content writer. Your job is to:\n",
        "    1. Take research findings and create engaging content\n",
        "    2. Write in a clear, accessible style\n",
        "    3. Include an introduction and conclusion\n",
        "    Keep your response under 300 words.\"\"\"\n",
        "\n",
        "    # Create prompt that includes the research and topic\n",
        "    prompt = f\"\"\"Topic: {topic}\n",
        "\n",
        "Research Findings:\n",
        "{research}\n",
        "\n",
        "Write a well-structured article based on the above research.\"\"\"\n",
        "\n",
        "    return call_llm(prompt, system)\n",
        "\n",
        "# Test it\n",
        "# draft = writer_agent(research, \"benefits of meditation\")\n",
        "# print(draft)\n"
      ],
      "metadata": {
        "id": "B2mawChcdxim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Define the editor agent\n",
        "\n",
        "def editor_agent(draft: str) -> str:\n",
        "    \"\"\"Edits and polishes content.\"\"\"\n",
        "    system = \"\"\"You are an editor. Your job is to:\n",
        "    1. Improve clarity and flow\n",
        "    2. Fix any grammatical issues\n",
        "    3. Add a compelling title\n",
        "    Return the polished version.\"\"\"\n",
        "\n",
        "    # Create prompt for editing\n",
        "    prompt = f\"\"\"Edit and polish the following draft:\n",
        "\n",
        "{draft}\n",
        "\n",
        "Provide a refined version with a clear title.\"\"\"\n",
        "\n",
        "    return call_llm(prompt, system)\n",
        "\n",
        "print(\"âœ… Agents defined!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaoPaofBd5U-",
        "outputId": "99e48f93-5081-4d68-e859-92ca29238065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Agents defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Create the pipeline function\n",
        "\n",
        "def run_content_pipeline(topic: str) -> dict:\n",
        "    \"\"\"Run the full content creation pipeline.\"\"\"\n",
        "    print(f\"ðŸ“š Starting pipeline for: '{topic}'\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Step 1: Research\n",
        "    print(\"\\nðŸ” Step 1: Researcher Agent working...\")\n",
        "    research = researcher_agent(topic)\n",
        "    print(f\"Research complete! ({len(research)} chars)\")\n",
        "\n",
        "    # Step 2: Writing\n",
        "    print(\"\\nâœï¸ Step 2: Writer Agent working...\")\n",
        "    draft = writer_agent(research, topic)\n",
        "    print(f\"Draft complete! ({len(draft)} chars)\")\n",
        "\n",
        "    # Step 3: Editing\n",
        "    print(\"\\nðŸ“ Step 3: Editor Agent working...\")\n",
        "    final = editor_agent(draft)\n",
        "    print(f\"Final version complete! ({len(final)} chars)\")\n",
        "\n",
        "    return {\n",
        "        \"topic\": topic,\n",
        "        \"research\": research,\n",
        "        \"draft\": draft,\n",
        "        \"final\": final\n",
        "    }\n",
        "\n",
        "# Run the pipeline\n",
        "# result = run_content_pipeline(\"The benefits of meditation\")\n",
        "# print(\"\\nðŸ“„ FINAL OUTPUT:\")\n",
        "# print(result[\"final\"])\n"
      ],
      "metadata": {
        "id": "MXJvh_nbeCnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a shared state structure\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional\n",
        "from datetime import datetime\n",
        "\n",
        "@dataclass\n",
        "class PipelineState:\n",
        "    \"\"\"Shared state for the content pipeline.\"\"\"\n",
        "    # Input\n",
        "    topic: str = \"\"\n",
        "\n",
        "    # Intermediate results\n",
        "    research: str = \"\"\n",
        "    draft: str = \"\"\n",
        "    final: str = \"\"\n",
        "\n",
        "    # Metadata\n",
        "    current_agent: str = \"\"\n",
        "    history: list = field(default_factory=list)\n",
        "    errors: list = field(default_factory=list)\n",
        "\n",
        "    def log(self, agent: str, message: str):\n",
        "        \"\"\"Log an action to history.\"\"\"\n",
        "        self.history.append({\n",
        "            \"agent\": agent,\n",
        "            \"message\": message,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        })\n",
        "        self.current_agent = agent\n",
        "\n",
        "# Test the state\n",
        "state = PipelineState(topic=\"AI in Healthcare\")\n",
        "state.log(\"researcher\", \"Starting research\")\n",
        "print(f\"Topic: {state.topic}\")\n",
        "print(f\"History: {state.history}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuE_vyaqeP0d",
        "outputId": "09055064-81cb-4988-b49c-d2a7f4cf8b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: AI in Healthcare\n",
            "History: [{'agent': 'researcher', 'message': 'Starting research', 'timestamp': '2026-01-30T15:15:48.368996'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Create agents that work with shared state\n",
        "\n",
        "def researcher_with_state(state: PipelineState) -> PipelineState:\n",
        "    \"\"\"Researcher that updates shared state.\"\"\"\n",
        "    state.log(\"researcher\", \"Beginning research\")\n",
        "\n",
        "    try:\n",
        "        # Call researcher_agent with state.topic\n",
        "        state.research = researcher_agent(state.topic)\n",
        "        state.log(\"researcher\", f\"Completed research ({len(state.research)} chars)\")\n",
        "    except Exception as e:\n",
        "        state.errors.append(f\"Researcher error: {e}\")\n",
        "\n",
        "    return state\n",
        "\n",
        "def writer_with_state(state: PipelineState) -> PipelineState:\n",
        "    \"\"\"Writer that uses shared state.\"\"\"\n",
        "    state.log(\"writer\", \"Beginning writing\")\n",
        "\n",
        "    if not state.research:\n",
        "        state.errors.append(\"Writer error: No research available\")\n",
        "        return state\n",
        "\n",
        "    try:\n",
        "        # Call writer_agent with state.research and state.topic\n",
        "        state.draft = writer_agent(state.research, state.topic)\n",
        "        state.log(\"writer\", f\"Completed draft ({len(state.draft)} chars)\")\n",
        "    except Exception as e:\n",
        "        state.errors.append(f\"Writer error: {e}\")\n",
        "\n",
        "    return state\n",
        "\n",
        "def editor_with_state(state: PipelineState) -> PipelineState:\n",
        "    \"\"\"Editor that uses shared state.\"\"\"\n",
        "    state.log(\"editor\", \"Beginning editing\")\n",
        "\n",
        "    if not state.draft:\n",
        "        state.errors.append(\"Editor error: No draft available\")\n",
        "        return state\n",
        "\n",
        "    try:\n",
        "        # Call editor_agent with state.draft\n",
        "        state.final = editor_agent(state.draft)\n",
        "        state.log(\"editor\", f\"Completed editing ({len(state.final)} chars)\")\n",
        "    except Exception as e:\n",
        "        state.errors.append(f\"Editor error: {e}\")\n",
        "\n",
        "    return state\n",
        "\n",
        "print(\"âœ… State-aware agents defined!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuRzcRAqeYKh",
        "outputId": "510e0e83-8f85-4d0f-b7d2-3a21d85fc443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… State-aware agents defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run pipeline with shared state\n",
        "\n",
        "def run_stateful_pipeline(topic: str) -> PipelineState:\n",
        "    \"\"\"Run pipeline with full state tracking.\"\"\"\n",
        "    # Initialize state\n",
        "    state = PipelineState(topic=topic)\n",
        "    state.log(\"orchestrator\", f\"Pipeline started for: {topic}\")\n",
        "\n",
        "    # Run agents in sequence\n",
        "    state = researcher_with_state(state)\n",
        "    state = writer_with_state(state)\n",
        "    state = editor_with_state(state)\n",
        "\n",
        "    state.log(\"orchestrator\", \"Pipeline completed\")\n",
        "    return state\n",
        "\n",
        "# Run it!\n",
        "# state = run_stateful_pipeline(\"Benefits of exercise\")\n",
        "\n",
        "# Show the history\n",
        "# print(\"ðŸ“œ PIPELINE HISTORY:\")\n",
        "# for entry in state.history:\n",
        "#     print(f\"[{entry['agent']}] {entry['message']}\")"
      ],
      "metadata": {
        "id": "mrIsqLv9eiG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define worker agents\n",
        "\n",
        "def math_agent(question: str) -> str:\n",
        "    \"\"\"Handles math-related questions.\"\"\"\n",
        "    system = \"You are a math expert. Solve math problems step by step. Be concise.\"\n",
        "    return call_llm(question, system)\n",
        "\n",
        "def science_agent(question: str) -> str:\n",
        "    \"\"\"Handles science-related questions.\"\"\"\n",
        "    system = \"You are a science expert. Explain scientific concepts clearly. Be concise.\"\n",
        "    return call_llm(question, system)\n",
        "\n",
        "def history_agent(question: str) -> str:\n",
        "    \"\"\"Handles history-related questions.\"\"\"\n",
        "    system = \"You are a history expert. Provide accurate historical information. Be concise.\"\n",
        "    return call_llm(question, system)\n",
        "\n",
        "def general_agent(question: str) -> str:\n",
        "    \"\"\"Handles general questions.\"\"\"\n",
        "    system = \"You are a helpful assistant. Answer questions clearly and concisely.\"\n",
        "    return call_llm(question, system)\n",
        "\n",
        "# Map of available agents\n",
        "AGENTS = {\n",
        "    \"math\": math_agent,\n",
        "    \"science\": science_agent,\n",
        "    \"history\": history_agent,\n",
        "    \"general\": general_agent\n",
        "}\n",
        "\n",
        "print(\"âœ… Worker agents defined!\")\n",
        "print(f\"Available agents: {list(AGENTS.keys())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsbsaHX8ek52",
        "outputId": "3853ddd0-af38-4715-d76e-6ad600ee7aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Worker agents defined!\n",
            "Available agents: ['math', 'science', 'history', 'general']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Create the Supervisor Agent\n",
        "\n",
        "def supervisor_agent(question: str) -> str:\n",
        "    \"\"\"Decides which agent should handle the question.\"\"\"\n",
        "    system = \"\"\"You are a supervisor that routes questions to the right expert.\n",
        "\n",
        "Available experts:\n",
        "- math: For calculations, equations, numbers\n",
        "- science: For physics, chemistry, biology, nature\n",
        "- history: For historical events, dates, people\n",
        "- general: For everything else\n",
        "\n",
        "Respond with ONLY the expert name (math, science, history, or general).\n",
        "No explanation, just the single word.\"\"\"\n",
        "\n",
        "    # Call the LLM to get routing decision\n",
        "    response = call_llm(question, system)\n",
        "\n",
        "    # Clean up response\n",
        "    agent_name = response.strip().lower()\n",
        "\n",
        "    # Validate - default to general if invalid\n",
        "    if agent_name not in AGENTS:\n",
        "        agent_name = \"general\"\n",
        "\n",
        "    return agent_name\n"
      ],
      "metadata": {
        "id": "S2gzLaPDetoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Complete Supervisor System\n",
        "\n",
        "def supervised_qa(question: str) -> dict:\n",
        "    \"\"\"Full supervised Q&A system.\"\"\"\n",
        "    print(f\"â“ Question: {question}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Step 1: Supervisor decides\n",
        "    agent_name = supervisor_agent(question)\n",
        "    print(f\"ðŸ‘” Supervisor chose: {agent_name}\")\n",
        "\n",
        "    # Step 2: Call the chosen agent\n",
        "    agent_fn = AGENTS[agent_name]\n",
        "    print(f\"ðŸ¤– Calling {agent_name} agent...\")\n",
        "\n",
        "    # Call the agent with the question\n",
        "    answer = agent_fn(question)\n",
        "\n",
        "    return {\n",
        "        \"question\": question,\n",
        "        \"routed_to\": agent_name,\n",
        "        \"answer\": answer\n",
        "    }\n"
      ],
      "metadata": {
        "id": "Lm_ex4rde3pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Build an Intent-based Router\n",
        "\n",
        "def classify_intent(user_input: str) -> str:\n",
        "    \"\"\"Classify user intent into categories.\"\"\"\n",
        "    system = \"\"\"Classify the user's intent into exactly one category:\n",
        "\n",
        "- QUESTION: User is asking for information\n",
        "- TASK: User wants something done (write, create, calculate)\n",
        "- CHAT: User is making conversation\n",
        "- COMPLAINT: User is expressing dissatisfaction\n",
        "\n",
        "Respond with ONLY the category name in caps.\"\"\"\n",
        "\n",
        "    # Call LLM to classify intent\n",
        "    response = call_llm(user_input, system)\n",
        "    intent = response.strip().upper()\n",
        "\n",
        "    # Validate\n",
        "    valid_intents = [\"QUESTION\", \"TASK\", \"CHAT\", \"COMPLAINT\"]\n",
        "    if intent not in valid_intents:\n",
        "        intent = \"CHAT\"\n",
        "\n",
        "    return intent\n",
        "\n",
        "print(\"âœ… Router defined!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pOcji25fAGT",
        "outputId": "c72d9694-1008-42a5-b041-f9cf3cbd98a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Router defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Complete Router System\n",
        "\n",
        "def route_and_handle(user_input: str) -> dict:\n",
        "    \"\"\"Route user input to appropriate handler.\"\"\"\n",
        "    print(f\"ðŸ“¨ Input: {user_input}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Classify intent\n",
        "    intent = classify_intent(user_input)\n",
        "    print(f\"ðŸ”€ Intent: {intent}\")\n",
        "\n",
        "    # Route to handler\n",
        "    handler = INTENT_HANDLERS[intent]\n",
        "    response = handler(user_input)\n",
        "\n",
        "    return {\n",
        "        \"input\": user_input,\n",
        "        \"intent\": intent,\n",
        "        \"response\": response\n",
        "    }\n"
      ],
      "metadata": {
        "id": "av_Ew9qufJ5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Research Team Implementation (Demo)\n",
        "\n",
        "@dataclass\n",
        "class ResearchState:\n",
        "    \"\"\"State for the research team.\"\"\"\n",
        "    query: str = \"\"\n",
        "    research_notes: str = \"\"\n",
        "    analysis: str = \"\"\n",
        "    final_report: str = \"\"\n",
        "    status: str = \"initialized\"\n",
        "    messages: list = field(default_factory=list)\n",
        "\n",
        "def research_team_researcher(state: ResearchState) -> ResearchState:\n",
        "    \"\"\"Research specialist.\"\"\"\n",
        "    state.messages.append(\"ðŸ“š Researcher: Starting research...\")\n",
        "    system = \"You are a research specialist. Gather comprehensive information.\"\n",
        "    state.research_notes = call_llm(f\"Research: {state.query}\", system)\n",
        "    state.messages.append(\"ðŸ“š Researcher: Research complete!\")\n",
        "    return state\n",
        "\n",
        "def research_team_analyst(state: ResearchState) -> ResearchState:\n",
        "    \"\"\"Analysis specialist.\"\"\"\n",
        "    state.messages.append(\"ðŸ” Analyst: Analyzing findings...\")\n",
        "    system = \"You are an analyst. Identify key insights and patterns.\"\n",
        "    state.analysis = call_llm(f\"Analyze:\\n{state.research_notes}\", system)\n",
        "    state.messages.append(\"ðŸ” Analyst: Analysis complete!\")\n",
        "    return state\n",
        "\n",
        "def research_team_writer(state: ResearchState) -> ResearchState:\n",
        "    \"\"\"Report writer.\"\"\"\n",
        "    state.messages.append(\"âœï¸ Writer: Creating report...\")\n",
        "    system = \"You are a report writer. Create a structured report.\"\n",
        "    prompt = f\"Topic: {state.query}\\nResearch: {state.research_notes}\\nAnalysis: {state.analysis}\"\n",
        "    state.final_report = call_llm(prompt, system)\n",
        "    state.messages.append(\"âœï¸ Writer: Report complete!\")\n",
        "    state.status = \"completed\"\n",
        "    return state\n",
        "\n",
        "def run_research_team(query: str) -> ResearchState:\n",
        "    \"\"\"Execute the full research team workflow.\"\"\"\n",
        "    print(f\"ðŸ”¬ Research Team Activated!\")\n",
        "    print(f\"ðŸ“‹ Query: {query}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    state = ResearchState(query=query)\n",
        "\n",
        "    state = research_team_researcher(state)\n",
        "    print(state.messages[-1])\n",
        "\n",
        "    state = research_team_analyst(state)\n",
        "    print(state.messages[-1])\n",
        "\n",
        "    state = research_team_writer(state)\n",
        "    print(state.messages[-1])\n",
        "\n",
        "    print(f\"\\nâœ… Status: {state.status}\")\n",
        "    return state\n",
        "\n",
        "# Run it!\n",
        "# result = run_research_team(\"The impact of AI on employment\")\n",
        "# print(\"\\nðŸ“„ FINAL REPORT:\")\n",
        "# print(result.final_report)"
      ],
      "metadata": {
        "id": "LOG8tMzhfQru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M-IpjGeQfU6z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}